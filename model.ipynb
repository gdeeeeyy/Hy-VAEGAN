{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d59d99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms.functional import resize\n",
    "from torch.nn.functional import interpolate\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db43cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),   # Accepts 3-channel RGB input\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(128 * 8 * 8, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128 * 8 * 8, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a882adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c41a17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 128 * 8 * 8)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # (B, 64, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1),    # (B, 3, 32, 32)\n",
    "            nn.Sigmoid()  # Ensures output in [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z).view(-1, 128, 8, 8)\n",
    "        return self.deconv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7be58d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Visualize Reconstructions\n",
    "def visualize(epoch, x, x_hat, n=6):\n",
    "    x = x[:n].cpu().detach().numpy()\n",
    "    x_hat = x_hat[:n].cpu().detach().numpy()\n",
    "    fig, axes = plt.subplots(2, n, figsize=(n*1.2, 3))\n",
    "    for i in range(n):\n",
    "        axes[0, i].imshow(x[i][0], cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(x_hat[i][0], cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "    plt.suptitle(f\"Epoch {epoch+1}: Top - Original | Bottom - Reconstructed\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d26a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),     # (B, 3, 32, 32) -> (B, 64, 16, 16)\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),   # (B, 64, 16, 16) -> (B, 128, 8, 8)\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "155494a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_components, dataloader, optimizers, epochs=10, save_dir='./eval_images'):\n",
    "    encoder, decoder, discriminator = model_components\n",
    "    opt_vae, opt_disc = optimizers\n",
    "    vae_losses, d_losses = [], []\n",
    "\n",
    "    real_dir = os.path.join(save_dir, 'real')\n",
    "    fake_dir = os.path.join(save_dir, 'fake')\n",
    "    os.makedirs(real_dir, exist_ok=True)\n",
    "    os.makedirs(fake_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, _) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            mu, logvar = encoder(x)\n",
    "            z = reparameterize(mu, logvar)\n",
    "            x_hat = decoder(z)\n",
    "\n",
    "            recon_loss = F.binary_cross_entropy(x_hat, x, reduction='sum') / batch_size\n",
    "            kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / batch_size\n",
    "            d_fake = discriminator(x_hat)\n",
    "            gan_loss = torch.mean(torch.log(d_fake + 1e-8))\n",
    "            vae_loss = recon_loss + kl_div - 0.001 * gan_loss\n",
    "\n",
    "            opt_vae.zero_grad()\n",
    "            vae_loss.backward()\n",
    "            opt_vae.step()\n",
    "\n",
    "            d_real = discriminator(x)\n",
    "            d_fake = discriminator(x_hat.detach())\n",
    "            d_loss = -torch.mean(torch.log(d_real + 1e-8) + torch.log(1 - d_fake + 1e-8))\n",
    "\n",
    "            opt_disc.zero_grad()\n",
    "            d_loss.backward()\n",
    "            opt_disc.step()\n",
    "\n",
    "            vae_losses.append(vae_loss.item())\n",
    "            d_losses.append(d_loss.item())\n",
    "\n",
    "            # Save images from first batch each epoch\n",
    "            # Save real inputs\n",
    "            for idx in range(batch_size):\n",
    "                save_image(x[idx].cpu(), os.path.join(real_dir, f'epoch{epoch+1}_img{idx+1}.png'), normalize=True)\n",
    "            # Save generated outputs\n",
    "            for idx in range(batch_size):\n",
    "                save_image(x_hat[idx].cpu(), os.path.join(fake_dir, f'epoch{epoch+1}_img{idx+1}.png'), normalize=True)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | VAE Loss: {vae_loss.item():.4f} | D Loss: {d_loss.item():.4f}\")\n",
    "        visualize(epoch, x, x_hat)\n",
    "\n",
    "    return vae_losses, d_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ab28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Initialize and Run Training\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "latent_dim = 20\n",
    "encoder = Encoder(latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "opt_vae = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "opt_disc = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "vae_losses, d_losses = train((encoder, decoder, discriminator), dataloader, (opt_vae, opt_disc), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 10 epochs\n",
    "epochs = [i for i in range(1, len(vae_losses) + 1)]\n",
    "\n",
    "# Ensure losses are on CPU and converted to numpy (if they are tensors)\n",
    "vae_losses_np = [loss.detach().cpu().item() if torch.is_tensor(loss) else loss for loss in vae_losses]\n",
    "d_losses_np = [loss.detach().cpu().item() if torch.is_tensor(loss) else loss for loss in d_losses]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, vae_losses_np, label='VAE Loss')\n",
    "plt.plot(epochs, d_losses_np, label='Discriminator Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score,\n",
    "    recall_score, f1_score, roc_curve, auc\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Evaluation Function\n",
    "def evaluate_discriminator(discriminator, dataloader, encoder, decoder, phase='Train'):\n",
    "    discriminator.eval()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in dataloader:\n",
    "            x = x.to(device)\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            # Generate fake images\n",
    "            mu, logvar = encoder(x)\n",
    "            z = reparameterize(mu, logvar)\n",
    "            x_fake = decoder(z)\n",
    "\n",
    "            # Discriminator outputs\n",
    "            real_scores = discriminator(x).view(-1)\n",
    "            fake_scores = discriminator(x_fake).view(-1)\n",
    "\n",
    "            y_true.extend([1] * batch_size + [0] * batch_size)  # 1 for real, 0 for fake\n",
    "            y_pred.extend(real_scores.cpu().numpy().tolist() + fake_scores.cpu().numpy().tolist())\n",
    "\n",
    "    # Threshold at 0.5 to get binary predictions\n",
    "    y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "\n",
    "    # Metrics\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "    acc = accuracy_score(y_true, y_pred_binary)\n",
    "    prec = precision_score(y_true, y_pred_binary)\n",
    "    rec = recall_score(y_true, y_pred_binary)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(f\"\\n=== {phase} Set Evaluation ===\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"AUC:       {roc_auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"{phase} - Confusion Matrix\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"{phase} - ROC Curve\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    discriminator.train()\n",
    "    encoder.train()\n",
    "    decoder.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1adfa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Evaluate on Train and Test Sets\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "evaluate_discriminator(discriminator, dataloader, encoder, decoder, phase='Train')\n",
    "evaluate_discriminator(discriminator, test_loader, encoder, decoder, phase='Test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization trick\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d664e95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch [1/10] | VAE Loss: 1806.4388 | D Loss: 0.4879\n",
      "Epoch [2/10] | VAE Loss: 1864.8618 | D Loss: 0.4830\n",
      "Epoch [3/10] | VAE Loss: 1881.4722 | D Loss: 0.1904\n",
      "Epoch [4/10] | VAE Loss: 1791.9443 | D Loss: 0.0390\n",
      "Epoch [5/10] | VAE Loss: 1767.8518 | D Loss: 0.0206\n",
      "Epoch [6/10] | VAE Loss: 1883.4524 | D Loss: 0.0478\n",
      "Epoch [7/10] | VAE Loss: 1736.4465 | D Loss: 0.0317\n",
      "Epoch [8/10] | VAE Loss: 1767.6279 | D Loss: 0.0793\n",
      "Epoch [9/10] | VAE Loss: 1878.8243 | D Loss: 0.0931\n",
      "Epoch [10/10] | VAE Loss: 1806.6317 | D Loss: 0.0265\n",
      "\n",
      "Total Training Time: 1.70 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/anaconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/tmp/ipykernel_27899/2410643277.py:90: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img_tensor = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FID Score: 71.2428\n",
      "Inception Score: 3.0169 ± 0.1106\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from PIL import Image\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "latent_dim = 100\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "save_dir = \"eval_images\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----------------- DATA -------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # range [0, 1]\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ----------------- MODELS -----------------\n",
    "encoder = Encoder(latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# ----------------- OPTIMIZERS -----------------\n",
    "opt_vae = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "opt_disc = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "# ----------------- TRAINING -----------------\n",
    "os.makedirs(f\"{save_dir}/real\", exist_ok=True)\n",
    "os.makedirs(f\"{save_dir}/fake\", exist_ok=True)\n",
    "start_time = time.time()\n",
    "\n",
    "image_id = 0  # for saving FID/IS image sets\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (x, _) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # === VAE Forward ===\n",
    "        mu, logvar = encoder(x)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        x_hat = decoder(z)\n",
    "\n",
    "        recon_loss = F.binary_cross_entropy(x_hat, x, reduction='sum') / batch_size\n",
    "        kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / batch_size\n",
    "        d_fake = discriminator(x_hat)\n",
    "        gan_loss = torch.mean(torch.log(d_fake + 1e-8))\n",
    "\n",
    "        vae_loss = recon_loss + kl_div - 0.001 * gan_loss\n",
    "\n",
    "        opt_vae.zero_grad()\n",
    "        vae_loss.backward()\n",
    "        opt_vae.step()\n",
    "\n",
    "        # === Discriminator ===\n",
    "        d_real = discriminator(x)\n",
    "        d_fake = discriminator(x_hat.detach())\n",
    "        d_loss = -torch.mean(torch.log(d_real + 1e-8) + torch.log(1 - d_fake + 1e-8))\n",
    "\n",
    "        opt_disc.zero_grad()\n",
    "        d_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Save real and fake images (first N only)\n",
    "        if epoch == epochs - 1 and image_id < 1000:\n",
    "            for idx in range(min(batch_size, 1000 - image_id)):\n",
    "                save_image(x[idx], f\"{save_dir}/real/{image_id:04d}.png\")\n",
    "                save_image(x_hat[idx], f\"{save_dir}/fake/{image_id:04d}.png\")\n",
    "                image_id += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | VAE Loss: {vae_loss.item():.4f} | D Loss: {d_loss.item():.4f}\")\n",
    "\n",
    "# ----------------- TIMER -----------------\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal Training Time: {(end_time - start_time)/60:.2f} minutes\")\n",
    "\n",
    "# ----------------- FID & IS Evaluation -----------------\n",
    "def preprocess_fid_image(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\").resize((299, 299))\n",
    "    img_tensor = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n",
    "    img_tensor = img_tensor.view(img.size[1], img.size[0], 3).permute(2, 0, 1)\n",
    "    return img_tensor.unsqueeze(0)\n",
    "\n",
    "def compute_fid_and_is(real_dir, fake_dir):\n",
    "    fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "    is_model = InceptionScore().to(device)\n",
    "\n",
    "    for path in sorted(os.listdir(real_dir)):\n",
    "        tensor = preprocess_fid_image(os.path.join(real_dir, path)).to(device)\n",
    "        fid.update(tensor, real=True)\n",
    "\n",
    "    for path in sorted(os.listdir(fake_dir)):\n",
    "        tensor = preprocess_fid_image(os.path.join(fake_dir, path)).to(device)\n",
    "        fid.update(tensor, real=False)\n",
    "        is_model.update(tensor)\n",
    "\n",
    "    fid_score = fid.compute().item()\n",
    "    is_score, is_std = is_model.compute()\n",
    "    return fid_score, is_score.item(), is_std.item()\n",
    "\n",
    "fid, is_score, is_std = compute_fid_and_is(f\"{save_dir}/real\", f\"{save_dir}/fake\")\n",
    "print(f\"\\nFID Score: {fid:.4f}\")\n",
    "print(f\"Inception Score: {is_score:.4f} ± {is_std:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
