{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms.functional import resize\n",
    "from torch.nn.functional import interpolate\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),   # Accepts 3-channel RGB input\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(128 * 8 * 8, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128 * 8 * 8, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 128 * 8 * 8)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # (B, 64, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1),    # (B, 3, 32, 32)\n",
    "            nn.Sigmoid()  # Ensures output in [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z).view(-1, 128, 8, 8)\n",
    "        return self.deconv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be58d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Visualize Reconstructions\n",
    "def visualize(epoch, x, x_hat, n=6):\n",
    "    x = x[:n].cpu().detach().numpy()\n",
    "    x_hat = x_hat[:n].cpu().detach().numpy()\n",
    "    fig, axes = plt.subplots(2, n, figsize=(n*1.2, 3))\n",
    "    for i in range(n):\n",
    "        axes[0, i].imshow(x[i][0], cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(x_hat[i][0], cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "    plt.suptitle(f\"Epoch {epoch+1}: Top - Original | Bottom - Reconstructed\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),     # (B, 3, 32, 32) -> (B, 64, 16, 16)\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),   # (B, 64, 16, 16) -> (B, 128, 8, 8)\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155494a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_components, dataloader, optimizers, epochs=10, save_dir='./eval_images'):\n",
    "    encoder, decoder, discriminator = model_components\n",
    "    opt_vae, opt_disc = optimizers\n",
    "    vae_losses, d_losses = [], []\n",
    "\n",
    "    real_dir = os.path.join(save_dir, 'real')\n",
    "    fake_dir = os.path.join(save_dir, 'fake')\n",
    "    os.makedirs(real_dir, exist_ok=True)\n",
    "    os.makedirs(fake_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, _) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            mu, logvar = encoder(x)\n",
    "            z = reparameterize(mu, logvar)\n",
    "            x_hat = decoder(z)\n",
    "\n",
    "            recon_loss = F.binary_cross_entropy(x_hat, x, reduction='sum') / batch_size\n",
    "            kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / batch_size\n",
    "            d_fake = discriminator(x_hat)\n",
    "            gan_loss = torch.mean(torch.log(d_fake + 1e-8))\n",
    "            vae_loss = recon_loss + kl_div - 0.001 * gan_loss\n",
    "\n",
    "            opt_vae.zero_grad()\n",
    "            vae_loss.backward()\n",
    "            opt_vae.step()\n",
    "\n",
    "            d_real = discriminator(x)\n",
    "            d_fake = discriminator(x_hat.detach())\n",
    "            d_loss = -torch.mean(torch.log(d_real + 1e-8) + torch.log(1 - d_fake + 1e-8))\n",
    "\n",
    "            opt_disc.zero_grad()\n",
    "            d_loss.backward()\n",
    "            opt_disc.step()\n",
    "\n",
    "            vae_losses.append(vae_loss.item())\n",
    "            d_losses.append(d_loss.item())\n",
    "\n",
    "            # Save images from first batch each epoch\n",
    "            # Save real inputs\n",
    "            for idx in range(batch_size):\n",
    "                save_image(x[idx].cpu(), os.path.join(real_dir, f'epoch{epoch+1}_img{idx+1}.png'), normalize=True)\n",
    "            # Save generated outputs\n",
    "            for idx in range(batch_size):\n",
    "                save_image(x_hat[idx].cpu(), os.path.join(fake_dir, f'epoch{epoch+1}_img{idx+1}.png'), normalize=True)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | VAE Loss: {vae_loss.item():.4f} | D Loss: {d_loss.item():.4f}\")\n",
    "        visualize(epoch, x, x_hat)\n",
    "\n",
    "    return vae_losses, d_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ab28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Initialize and Run Training\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "latent_dim = 20\n",
    "encoder = Encoder(latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "opt_vae = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "opt_disc = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "vae_losses, d_losses = train((encoder, decoder, discriminator), dataloader, (opt_vae, opt_disc), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 10 epochs\n",
    "epochs = [i for i in range(1, len(vae_losses) + 1)]\n",
    "\n",
    "# Ensure losses are on CPU and converted to numpy (if they are tensors)\n",
    "vae_losses_np = [loss.detach().cpu().item() if torch.is_tensor(loss) else loss for loss in vae_losses]\n",
    "d_losses_np = [loss.detach().cpu().item() if torch.is_tensor(loss) else loss for loss in d_losses]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, vae_losses_np, label='VAE Loss')\n",
    "plt.plot(epochs, d_losses_np, label='Discriminator Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score,\n",
    "    recall_score, f1_score, roc_curve, auc\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Evaluation Function\n",
    "def evaluate_discriminator(discriminator, dataloader, encoder, decoder, phase='Train'):\n",
    "    discriminator.eval()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in dataloader:\n",
    "            x = x.to(device)\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            # Generate fake images\n",
    "            mu, logvar = encoder(x)\n",
    "            z = reparameterize(mu, logvar)\n",
    "            x_fake = decoder(z)\n",
    "\n",
    "            # Discriminator outputs\n",
    "            real_scores = discriminator(x).view(-1)\n",
    "            fake_scores = discriminator(x_fake).view(-1)\n",
    "\n",
    "            y_true.extend([1] * batch_size + [0] * batch_size)  # 1 for real, 0 for fake\n",
    "            y_pred.extend(real_scores.cpu().numpy().tolist() + fake_scores.cpu().numpy().tolist())\n",
    "\n",
    "    # Threshold at 0.5 to get binary predictions\n",
    "    y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "\n",
    "    # Metrics\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "    acc = accuracy_score(y_true, y_pred_binary)\n",
    "    prec = precision_score(y_true, y_pred_binary)\n",
    "    rec = recall_score(y_true, y_pred_binary)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(f\"\\n=== {phase} Set Evaluation ===\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"AUC:       {roc_auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"{phase} - Confusion Matrix\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"{phase} - ROC Curve\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    discriminator.train()\n",
    "    encoder.train()\n",
    "    decoder.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1adfa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Evaluate on Train and Test Sets\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "evaluate_discriminator(discriminator, dataloader, encoder, decoder, phase='Train')\n",
    "evaluate_discriminator(discriminator, test_loader, encoder, decoder, phase='Test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization trick\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d664e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from PIL import Image\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "latent_dim = 100\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "save_dir = \"eval_images\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----------------- DATA -------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # range [0, 1]   \n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ----------------- MODELS -----------------\n",
    "encoder = Encoder(latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# ----------------- OPTIMIZERS -----------------\n",
    "opt_vae = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "opt_disc = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "# ----------------- TRAINING -----------------\n",
    "os.makedirs(f\"{save_dir}/real\", exist_ok=True)\n",
    "os.makedirs(f\"{save_dir}/fake\", exist_ok=True)\n",
    "start_time = time.time()\n",
    "\n",
    "image_id = 0  # for saving FID/IS image sets\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (x, _) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # === VAE Forward ===\n",
    "        mu, logvar = encoder(x)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        x_hat = decoder(z)\n",
    "\n",
    "        recon_loss = F.binary_cross_entropy(x_hat, x, reduction='sum') / batch_size\n",
    "        kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / batch_size\n",
    "        d_fake = discriminator(x_hat)\n",
    "        gan_loss = torch.mean(torch.log(d_fake + 1e-8))\n",
    "\n",
    "        vae_loss = recon_loss + kl_div - 0.001 * gan_loss\n",
    "\n",
    "        opt_vae.zero_grad()\n",
    "        vae_loss.backward()\n",
    "        opt_vae.step()\n",
    "\n",
    "        # === Discriminator ===\n",
    "        d_real = discriminator(x)\n",
    "        d_fake = discriminator(x_hat.detach())\n",
    "        d_loss = -torch.mean(torch.log(d_real + 1e-8) + torch.log(1 - d_fake + 1e-8))\n",
    "\n",
    "        opt_disc.zero_grad()\n",
    "        d_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Save real and fake images (first N only)\n",
    "        if epoch == epochs - 1 and image_id < 1000:\n",
    "            for idx in range(min(batch_size, 1000 - image_id)):\n",
    "                save_image(x[idx], f\"{save_dir}/real/{image_id:04d}.png\")\n",
    "                save_image(x_hat[idx], f\"{save_dir}/fake/{image_id:04d}.png\")\n",
    "                image_id += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | VAE Loss: {vae_loss.item():.4f} | D Loss: {d_loss.item():.4f}\")\n",
    "\n",
    "# ----------------- TIMER -----------------\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal Training Time: {(end_time - start_time)/60:.2f} minutes\")\n",
    "\n",
    "# ----------------- FID & IS Evaluation -----------------\n",
    "def preprocess_fid_image(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\").resize((299, 299))\n",
    "    img_tensor = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n",
    "    img_tensor = img_tensor.view(img.size[1], img.size[0], 3).permute(2, 0, 1)\n",
    "    return img_tensor.unsqueeze(0)\n",
    "\n",
    "def compute_fid_and_is(real_dir, fake_dir):\n",
    "    fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "    is_model = InceptionScore().to(device)\n",
    "\n",
    "    for path in sorted(os.listdir(real_dir)):\n",
    "        tensor = preprocess_fid_image(os.path.join(real_dir, path)).to(device)\n",
    "        fid.update(tensor, real=True)\n",
    "\n",
    "    for path in sorted(os.listdir(fake_dir)):\n",
    "        tensor = preprocess_fid_image(os.path.join(fake_dir, path)).to(device)\n",
    "        fid.update(tensor, real=False)\n",
    "        is_model.update(tensor)\n",
    "\n",
    "    fid_score = fid.compute().item()\n",
    "    is_score, is_std = is_model.compute()\n",
    "    return fid_score, is_score.item(), is_std.item()\n",
    "\n",
    "fid, is_score, is_std = compute_fid_and_is(f\"{save_dir}/real\", f\"{save_dir}/fake\")\n",
    "print(f\"\\nFID Score: {fid:.4f}\")\n",
    "print(f\"Inception Score: {is_score:.4f} ± {is_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ca2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "\n",
    "# --------------------------- CONFIG ---------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "latent_dim = 100\n",
    "image_size = 32\n",
    "image_channels = 3\n",
    "\n",
    "# --------------------------- DATA ---------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# --------------------------- VAE ---------------------------\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(128 * 8 * 8, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128 * 8 * 8, latent_dim)\n",
    "        self.decoder_input = nn.Linear(latent_dim, 128 * 8 * 8)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_enc = self.encoder(x)\n",
    "        mu = self.fc_mu(x_enc)\n",
    "        logvar = self.fc_logvar(x_enc)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_dec = self.decoder_input(z).view(-1, 128, 8, 8)\n",
    "        return self.decoder(x_dec), mu, logvar\n",
    "\n",
    "# --------------------------- GAN ---------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * 8 * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (128, 8, 8)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ---------------------- FID & IS UTILS ----------------------\n",
    "def preprocess_image(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\").resize((299, 299))\n",
    "    tensor = transforms.ToTensor()(img) * 255\n",
    "    return tensor.to(torch.uint8).unsqueeze(0)\n",
    "\n",
    "def compute_fid_is(real_dir, fake_dir):\n",
    "    fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "    is_score = InceptionScore().to(device)\n",
    "    for path in sorted(os.listdir(real_dir)):\n",
    "        fid.update(preprocess_image(os.path.join(real_dir, path)).to(device), real=True)\n",
    "    for path in sorted(os.listdir(fake_dir)):\n",
    "        img_tensor = preprocess_image(os.path.join(fake_dir, path)).to(device)\n",
    "        fid.update(img_tensor, real=False)\n",
    "        is_score.update(img_tensor)\n",
    "    return fid.compute().item(), *is_score.compute()\n",
    "\n",
    "# ------------------ TRAINING FUNCTIONS ------------------\n",
    "def train_vae(model, dataloader, epochs=10):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model.train()\n",
    "    os.makedirs(\"vae_outputs\", exist_ok=True)\n",
    "    start = time.time()\n",
    "    image_id = 0\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, _ in dataloader:\n",
    "            x = x.to(device)\n",
    "            x_hat, mu, logvar = model(x)\n",
    "            recon_loss = F.binary_cross_entropy(x_hat, x, reduction='sum') / x.size(0)\n",
    "            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "            loss = recon_loss + kl_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            if epoch == epochs - 1:\n",
    "                for i in range(min(x.size(0), 1000 - image_id)):\n",
    "                    save_image(x[i], f\"vae_outputs/real_{image_id:04d}.png\")\n",
    "                    save_image(x_hat[i], f\"vae_outputs/fake_{image_id:04d}.png\")\n",
    "                    image_id += 1\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] VAE Loss: {total_loss/len(dataloader):.4f}\")\n",
    "    return time.time() - start\n",
    "\n",
    "def train_gan(generator, discriminator, dataloader, epochs=10):\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "    opt_g = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_d = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    os.makedirs(\"gan_outputs\", exist_ok=True)\n",
    "    start = time.time()\n",
    "    image_id = 0\n",
    "    for epoch in range(epochs):\n",
    "        total_d_loss, total_g_loss = 0, 0\n",
    "        for x, _ in dataloader:\n",
    "            x = x.to(device)\n",
    "            batch_size = x.size(0)\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            opt_d.zero_grad()\n",
    "            outputs_real = discriminator(x)\n",
    "            d_loss_real = criterion(outputs_real, real_labels)\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_imgs = generator(z)\n",
    "            outputs_fake = discriminator(fake_imgs.detach())\n",
    "            d_loss_fake = criterion(outputs_fake, fake_labels)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            opt_d.step()\n",
    "\n",
    "            # Train Generator\n",
    "            opt_g.zero_grad()\n",
    "            outputs = discriminator(fake_imgs)\n",
    "            g_loss = criterion(outputs, real_labels)\n",
    "            g_loss.backward()\n",
    "            opt_g.step()\n",
    "\n",
    "            total_d_loss += d_loss.item()\n",
    "            total_g_loss += g_loss.item()\n",
    "\n",
    "            if epoch == epochs - 1:\n",
    "                for i in range(min(batch_size, 1000 - image_id)):\n",
    "                    save_image(x[i], f\"gan_outputs/real_{image_id:04d}.png\")\n",
    "                    save_image(fake_imgs[i], f\"gan_outputs/fake_{image_id:04d}.png\")\n",
    "                    image_id += 1\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] GAN D Loss: {total_d_loss/len(dataloader):.4f} | G Loss: {total_g_loss/len(dataloader):.4f}\")\n",
    "    return time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c005be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = VAE(latent_dim)\n",
    "gan_gen = Generator(latent_dim)\n",
    "gan_disc = Discriminator()\n",
    "\n",
    "print(\"Training VAE...\")\n",
    "time_vae = train_vae(vae_model, dataloader, epochs=100)\n",
    "fid_vae, is_vae, is_std_vae = compute_fid_is(\"vae_outputs\", \"vae_outputs\")\n",
    "print(f\"\\n[VAE] Training Time: {time_vae:.2f} sec | FID: {fid_vae:.2f} | IS: {is_vae:.2f} ± {is_std_vae:.2f}\")\n",
    "\n",
    "print(\"\\nTraining GAN...\")\n",
    "time_gan = train_gan(gan_gen, gan_disc, dataloader, epochs=100)\n",
    "fid_gan, is_gan, is_std_gan = compute_fid_is(\"gan_outputs\", \"gan_outputs\")\n",
    "print(f\"\\n[GAN] Training Time: {time_gan:.2f} sec | FID: {fid_gan:.2f} | IS: {is_gan:.2f} ± {is_std_gan:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbbaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
